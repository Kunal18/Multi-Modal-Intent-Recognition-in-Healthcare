{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f8cc1ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5ee0f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>merged_prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when i remember her i feel down</td>\n",
       "      <td>Emotional and mental health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>when i carry heavy things i feel like breaking...</td>\n",
       "      <td>Hair and skin issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>there is too much pain when i move my arm</td>\n",
       "      <td>Chest pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my son had his lip pierced and it is swollen a...</td>\n",
       "      <td>Wound and injury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>my muscles in my lower back are aching</td>\n",
       "      <td>Wound and injury</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              phrase  \\\n",
       "0                    when i remember her i feel down   \n",
       "1  when i carry heavy things i feel like breaking...   \n",
       "2          there is too much pain when i move my arm   \n",
       "3  my son had his lip pierced and it is swollen a...   \n",
       "4             my muscles in my lower back are aching   \n",
       "\n",
       "                 merged_prompt  \n",
       "0  Emotional and mental health  \n",
       "1         Hair and skin issues  \n",
       "2                   Chest pain  \n",
       "3             Wound and injury  \n",
       "4             Wound and injury  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data and select relevant columns\n",
    "train_data = pd.read_csv(\"/Users/kunalindore/Library/CloudStorage/OneDrive-NortheasternUniversity/Capstone/Multi-Modal-Intent-Recognition-in-Healthcare/project/data/metadata_train.csv\")\n",
    "train_data = train_data[[\"phrase\", \"merged_prompt\"]]\n",
    "train_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54397c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>merged_prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i have a sharp pain in my lower stomach</td>\n",
       "      <td>Digestive issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dont cry</td>\n",
       "      <td>Muscle and joint pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>when i get out of bed in the morning my body f...</td>\n",
       "      <td>General weakness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i have a great pain in my thorax from heart in...</td>\n",
       "      <td>Chest pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i have a hard muscle pain since i went to the gym</td>\n",
       "      <td>Muscle and joint pain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              phrase          merged_prompt\n",
       "0            i have a sharp pain in my lower stomach       Digestive issues\n",
       "1                                           dont cry  Muscle and joint pain\n",
       "2  when i get out of bed in the morning my body f...       General weakness\n",
       "3  i have a great pain in my thorax from heart in...             Chest pain\n",
       "4  i have a hard muscle pain since i went to the gym  Muscle and joint pain"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data and select relevant columns\n",
    "test_data = pd.read_csv(\"/Users/kunalindore/Library/CloudStorage/OneDrive-NortheasternUniversity/Capstone/Multi-Modal-Intent-Recognition-in-Healthcare/project/data/metadata_test.csv\")\n",
    "test_data = test_data[[\"phrase\", \"merged_prompt\"]]\n",
    "test_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75376835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>merged_prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i read a book for along time and when i finish...</td>\n",
       "      <td>Headache</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my hair is falling out in huge amount</td>\n",
       "      <td>Hair and skin issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my foot is hurting so much</td>\n",
       "      <td>Leg and foot pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i feel pain in the lower back</td>\n",
       "      <td>Neck, back or spinal issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i feel pain in my stomach</td>\n",
       "      <td>Digestive issues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              phrase  \\\n",
       "0  i read a book for along time and when i finish...   \n",
       "1              my hair is falling out in huge amount   \n",
       "2                         my foot is hurting so much   \n",
       "3                      i feel pain in the lower back   \n",
       "4                          i feel pain in my stomach   \n",
       "\n",
       "                 merged_prompt  \n",
       "0                     Headache  \n",
       "1         Hair and skin issues  \n",
       "2            Leg and foot pain  \n",
       "3  Neck, back or spinal issues  \n",
       "4             Digestive issues  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data and select relevant columns\n",
    "validate_data = pd.read_csv(\"/Users/kunalindore/Library/CloudStorage/OneDrive-NortheasternUniversity/Capstone/Multi-Modal-Intent-Recognition-in-Healthcare/project/data/metadata_validate.csv\")\n",
    "validate_data = validate_data[[\"phrase\", \"merged_prompt\"]]\n",
    "validate_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0025069a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hair and skin issues           764\n",
      "Wound and injury               664\n",
      "Muscle and joint pain          526\n",
      "Leg and foot pain              472\n",
      "Respiratory issue              470\n",
      "Sensory issues                 458\n",
      "Neck, back or spinal issues    451\n",
      "Shoulder pain                  278\n",
      "Dizziness and vertigo          256\n",
      "Chest pain                     231\n",
      "Headache                       231\n",
      "Digestive issues               230\n",
      "Feeling cold/hot               230\n",
      "General weakness               215\n",
      "Internal pain                  215\n",
      "Emotional and mental health    204\n",
      "Name: merged_prompt, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the number of rows for each merged_prompt class\n",
    "train_class_counts = train_data['merged_prompt'].value_counts()\n",
    "print(train_class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904563e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hair and skin issues           45\n",
      "Wound and injury               42\n",
      "Muscle and joint pain          39\n",
      "Sensory issues                 34\n",
      "Leg and foot pain              29\n",
      "Neck, back or spinal issues    28\n",
      "Chest pain                     25\n",
      "Shoulder pain                  21\n",
      "Internal pain                  21\n",
      "Respiratory issue              19\n",
      "Feeling cold/hot               18\n",
      "Digestive issues               16\n",
      "Headache                       16\n",
      "General weakness               10\n",
      "Emotional and mental health    10\n",
      "Dizziness and vertigo           8\n",
      "Name: merged_prompt, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the number of rows for each merged_prompt class\n",
    "test_class_counts = test_data['merged_prompt'].value_counts()\n",
    "print(test_class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f67c96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hair and skin issues           45\n",
      "Wound and injury               38\n",
      "Respiratory issue              37\n",
      "Muscle and joint pain          35\n",
      "Neck, back or spinal issues    31\n",
      "Leg and foot pain              27\n",
      "Sensory issues                 24\n",
      "Shoulder pain                  21\n",
      "Dizziness and vertigo          19\n",
      "Emotional and mental health    17\n",
      "Chest pain                     17\n",
      "Headache                       16\n",
      "General weakness               16\n",
      "Digestive issues               15\n",
      "Feeling cold/hot               15\n",
      "Internal pain                  12\n",
      "Name: merged_prompt, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the number of rows for each merged_prompt class\n",
    "validate_class_counts = validate_data['merged_prompt'].value_counts()\n",
    "print(validate_class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deacf497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess text\n",
    "def preprocess_text(text):\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    cleaned_text = cleaned_text.lower()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lemma = WordNetLemmatizer()\n",
    "    tokens = word_tokenize(cleaned_text)\n",
    "    cleaned_text = ' '.join([word for word in tokens if word not in stop_words])\n",
    "    cleaned_text = ' '.join([lemma.lemmatize(word) for word in cleaned_text.split()])\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9180c124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "train_data.rename(columns={\"merged_prompt\": \"intent\", \"phrase\": \"audio_phrase\"}, inplace=True)\n",
    "test_data.rename(columns={\"merged_prompt\": \"intent\", \"phrase\": \"audio_phrase\"}, inplace=True)\n",
    "validate_data.rename(columns={\"merged_prompt\": \"intent\", \"phrase\": \"audio_phrase\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be6a631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess text\n",
    "train_data['audio_phrase'] = train_data['audio_phrase'].apply(preprocess_text)\n",
    "test_data['audio_phrase'] = test_data['audio_phrase'].apply(preprocess_text)\n",
    "validate_data['audio_phrase'] = validate_data['audio_phrase'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d725d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "train_data['intent'] = label_encoder.fit_transform(train_data['intent'])\n",
    "test_data['intent'] = label_encoder.fit_transform(test_data['intent'])\n",
    "validate_data['intent'] = label_encoder.fit_transform(validate_data['intent'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4709bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label mapping: {0: 'Chest pain', 1: 'Digestive issues', 2: 'Dizziness and vertigo', 3: 'Emotional and mental health', 4: 'Feeling cold/hot', 5: 'General weakness', 6: 'Hair and skin issues', 7: 'Headache', 8: 'Internal pain', 9: 'Leg and foot pain', 10: 'Muscle and joint pain', 11: 'Neck, back or spinal issues', 12: 'Respiratory issue', 13: 'Sensory issues', 14: 'Shoulder pain', 15: 'Wound and injury'}\n"
     ]
    }
   ],
   "source": [
    "label_mapping = dict(zip(range(len(label_encoder.classes_)), label_encoder.classes_))\n",
    "print(\"Label mapping:\", label_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82b1b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(sublinear_tf=True, smooth_idf=True)\n",
    "X_train = tfidf_vectorizer.fit_transform(train_data['audio_phrase'])\n",
    "y_train = train_data['intent']\n",
    "X_test = tfidf_vectorizer.transform(test_data['audio_phrase'])\n",
    "y_test = test_data['intent']\n",
    "X_val = tfidf_vectorizer.transform(validate_data['audio_phrase'])\n",
    "y_val = validate_data['intent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf707ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       231\n",
      "           1       0.97      1.00      0.98       230\n",
      "           2       1.00      1.00      1.00       256\n",
      "           3       1.00      1.00      1.00       204\n",
      "           4       1.00      1.00      1.00       230\n",
      "           5       1.00      1.00      1.00       215\n",
      "           6       1.00      1.00      1.00       764\n",
      "           7       1.00      1.00      1.00       231\n",
      "           8       1.00      0.96      0.98       215\n",
      "           9       1.00      1.00      1.00       472\n",
      "          10       1.00      1.00      1.00       526\n",
      "          11       1.00      1.00      1.00       451\n",
      "          12       1.00      1.00      1.00       470\n",
      "          13       1.00      1.00      1.00       458\n",
      "          14       1.00      1.00      1.00       278\n",
      "          15       1.00      1.00      1.00       664\n",
      "\n",
      "    accuracy                           1.00      5895\n",
      "   macro avg       1.00      1.00      1.00      5895\n",
      "weighted avg       1.00      1.00      1.00      5895\n",
      "\n",
      "Test data classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        25\n",
      "           1       1.00      1.00      1.00        16\n",
      "           2       1.00      1.00      1.00         8\n",
      "           3       1.00      1.00      1.00        10\n",
      "           4       1.00      1.00      1.00        18\n",
      "           5       0.91      1.00      0.95        10\n",
      "           6       1.00      1.00      1.00        45\n",
      "           7       1.00      1.00      1.00        16\n",
      "           8       1.00      1.00      1.00        21\n",
      "           9       1.00      1.00      1.00        29\n",
      "          10       1.00      0.97      0.99        39\n",
      "          11       1.00      1.00      1.00        28\n",
      "          12       1.00      1.00      1.00        19\n",
      "          13       1.00      1.00      1.00        34\n",
      "          14       1.00      1.00      1.00        21\n",
      "          15       1.00      1.00      1.00        42\n",
      "\n",
      "    accuracy                           1.00       381\n",
      "   macro avg       0.99      1.00      1.00       381\n",
      "weighted avg       1.00      1.00      1.00       381\n",
      "\n",
      "Validation data classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        17\n",
      "           1       0.94      1.00      0.97        15\n",
      "           2       1.00      1.00      1.00        19\n",
      "           3       1.00      1.00      1.00        17\n",
      "           4       1.00      1.00      1.00        15\n",
      "           5       1.00      1.00      1.00        16\n",
      "           6       1.00      1.00      1.00        45\n",
      "           7       1.00      1.00      1.00        16\n",
      "           8       1.00      0.92      0.96        12\n",
      "           9       1.00      1.00      1.00        27\n",
      "          10       1.00      1.00      1.00        35\n",
      "          11       1.00      1.00      1.00        31\n",
      "          12       1.00      1.00      1.00        37\n",
      "          13       1.00      1.00      1.00        24\n",
      "          14       1.00      1.00      1.00        21\n",
      "          15       1.00      1.00      1.00        38\n",
      "\n",
      "    accuracy                           1.00       385\n",
      "   macro avg       1.00      0.99      1.00       385\n",
      "weighted avg       1.00      1.00      1.00       385\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_train = random_forest.predict(X_train)\n",
    "y_pred_test = random_forest.predict(X_test)\n",
    "y_pred_val = random_forest.predict(X_val)\n",
    "\n",
    "print(\"Train data classification report:\")\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "\n",
    "print(\"Test data classification report:\")\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "\n",
    "print(\"Validation data classification report:\")\n",
    "print(classification_report(y_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05fbdbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implement Random Forest\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "random_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48e9dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=RandomForestClassifier(random_state=42),\n",
       "             param_grid={'max_depth': [None, 10, 20],\n",
       "                         'min_samples_leaf': [1, 2, 4],\n",
       "                         'min_samples_split': [2, 5, 10],\n",
       "                         'n_estimators': [50, 100, 200]})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=random_forest, param_grid=param_grid, cv=10)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68cbb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random_forest = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf98b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172e7d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       231\n",
      "           1       0.97      1.00      0.98       230\n",
      "           2       1.00      1.00      1.00       256\n",
      "           3       1.00      1.00      1.00       204\n",
      "           4       1.00      1.00      1.00       230\n",
      "           5       1.00      1.00      1.00       215\n",
      "           6       1.00      1.00      1.00       764\n",
      "           7       1.00      1.00      1.00       231\n",
      "           8       1.00      0.96      0.98       215\n",
      "           9       1.00      1.00      1.00       472\n",
      "          10       1.00      1.00      1.00       526\n",
      "          11       1.00      1.00      1.00       451\n",
      "          12       1.00      1.00      1.00       470\n",
      "          13       1.00      1.00      1.00       458\n",
      "          14       1.00      1.00      1.00       278\n",
      "          15       1.00      1.00      1.00       664\n",
      "\n",
      "    accuracy                           1.00      5895\n",
      "   macro avg       1.00      1.00      1.00      5895\n",
      "weighted avg       1.00      1.00      1.00      5895\n",
      "\n",
      "Test data classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        25\n",
      "           1       1.00      1.00      1.00        16\n",
      "           2       1.00      1.00      1.00         8\n",
      "           3       1.00      1.00      1.00        10\n",
      "           4       1.00      1.00      1.00        18\n",
      "           5       0.91      1.00      0.95        10\n",
      "           6       1.00      1.00      1.00        45\n",
      "           7       1.00      1.00      1.00        16\n",
      "           8       1.00      1.00      1.00        21\n",
      "           9       1.00      1.00      1.00        29\n",
      "          10       1.00      0.97      0.99        39\n",
      "          11       1.00      1.00      1.00        28\n",
      "          12       1.00      1.00      1.00        19\n",
      "          13       1.00      1.00      1.00        34\n",
      "          14       1.00      1.00      1.00        21\n",
      "          15       1.00      1.00      1.00        42\n",
      "\n",
      "    accuracy                           1.00       381\n",
      "   macro avg       0.99      1.00      1.00       381\n",
      "weighted avg       1.00      1.00      1.00       381\n",
      "\n",
      "Validation data classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        17\n",
      "           1       0.94      1.00      0.97        15\n",
      "           2       1.00      1.00      1.00        19\n",
      "           3       1.00      1.00      1.00        17\n",
      "           4       1.00      1.00      1.00        15\n",
      "           5       1.00      1.00      1.00        16\n",
      "           6       1.00      1.00      1.00        45\n",
      "           7       1.00      1.00      1.00        16\n",
      "           8       1.00      0.92      0.96        12\n",
      "           9       1.00      1.00      1.00        27\n",
      "          10       1.00      1.00      1.00        35\n",
      "          11       1.00      1.00      1.00        31\n",
      "          12       1.00      1.00      1.00        37\n",
      "          13       1.00      1.00      1.00        24\n",
      "          14       1.00      1.00      1.00        21\n",
      "          15       1.00      1.00      1.00        38\n",
      "\n",
      "    accuracy                           1.00       385\n",
      "   macro avg       1.00      0.99      1.00       385\n",
      "weighted avg       1.00      1.00      1.00       385\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "y_pred_train = best_random_forest.predict(X_train)\n",
    "y_pred_test = best_random_forest.predict(X_test)\n",
    "y_pred_val = best_random_forest.predict(X_val)\n",
    "\n",
    "print(\"Train data classification report:\")\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "\n",
    "print(\"Test data classification report:\")\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "\n",
    "print(\"Validation data classification report:\")\n",
    "print(classification_report(y_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938ddea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.9/site-packages (1.1.1)\r\n"
     ]
    }
   ],
   "source": [
    "# !pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9766c5cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/kunalindore/Library/CloudStorage/OneDrive-NortheasternUniversity/Capstone/Multi-Modal-Intent-Recognition-in-Healthcare/project/models/label_encoder.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import joblib\n",
    "# joblib.dump(best_random_forest, '/Users/kunalindore/Library/CloudStorage/OneDrive-NortheasternUniversity/Capstone/Multi-Modal-Intent-Recognition-in-Healthcare/project/models/random_forest_model.pkl',protocol=4)\n",
    "# joblib.dump(tfidf_vectorizer, '/Users/kunalindore/Library/CloudStorage/OneDrive-NortheasternUniversity/Capstone/Multi-Modal-Intent-Recognition-in-Healthcare/project/models/tfidf_vectorizer.pkl')\n",
    "# joblib.dump(label_encoder, '/Users/kunalindore/Library/CloudStorage/OneDrive-NortheasternUniversity/Capstone/Multi-Modal-Intent-Recognition-in-Healthcare/project/models/label_encoder.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
