{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7890939,"sourceType":"datasetVersion","datasetId":4632836},{"sourceId":7925788,"sourceType":"datasetVersion","datasetId":4658050}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvidia-smi","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! pip install --upgrade tensorflow keras librosa==0.9.1","metadata":{"execution":{"iopub.status.busy":"2024-03-20T02:20:15.518246Z","iopub.execute_input":"2024-03-20T02:20:15.518557Z","iopub.status.idle":"2024-03-20T02:21:44.929357Z","shell.execute_reply.started":"2024-03-20T02:20:15.518526Z","shell.execute_reply":"2024-03-20T02:21:44.928301Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.15.0)\nCollecting tensorflow\n  Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\nRequirement already satisfied: keras in /opt/conda/lib/python3.10/site-packages (3.0.5)\nCollecting keras\n  Downloading keras-3.1.1-py3-none-any.whl.metadata (5.6 kB)\nCollecting librosa==0.9.1\n  Downloading librosa-0.9.1-py3-none-any.whl.metadata (6.9 kB)\nRequirement already satisfied: audioread>=2.1.5 in /opt/conda/lib/python3.10/site-packages (from librosa==0.9.1) (3.0.1)\nRequirement already satisfied: numpy>=1.17.0 in /opt/conda/lib/python3.10/site-packages (from librosa==0.9.1) (1.26.4)\nRequirement already satisfied: scipy>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from librosa==0.9.1) (1.11.4)\nRequirement already satisfied: scikit-learn>=0.19.1 in /opt/conda/lib/python3.10/site-packages (from librosa==0.9.1) (1.2.2)\nRequirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.10/site-packages (from librosa==0.9.1) (1.3.2)\nRequirement already satisfied: decorator>=4.0.10 in /opt/conda/lib/python3.10/site-packages (from librosa==0.9.1) (5.1.1)\nCollecting resampy>=0.2.2 (from librosa==0.9.1)\n  Downloading resampy-0.4.3-py3-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: numba>=0.45.1 in /opt/conda/lib/python3.10/site-packages (from librosa==0.9.1) (0.58.1)\nRequirement already satisfied: soundfile>=0.10.2 in /opt/conda/lib/python3.10/site-packages (from librosa==0.9.1) (0.12.1)\nRequirement already satisfied: pooch>=1.0 in /opt/conda/lib/python3.10/site-packages (from librosa==0.9.1) (1.8.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from librosa==0.9.1) (21.3)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.5.26)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=3.10.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.10.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.6)\nCollecting ml-dtypes~=0.3.1 (from tensorflow)\n  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.31.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (69.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.9.0)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.14.1)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.51.1)\nCollecting tensorboard<2.17,>=2.16 (from tensorflow)\n  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.35.0)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras) (13.7.0)\nRequirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras) (0.0.7)\nCollecting optree (from keras)\n  Downloading optree-0.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (45 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.3/45.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\nRequirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.45.1->librosa==0.9.1) (0.41.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->librosa==0.9.1) (3.1.1)\nRequirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.0->librosa==0.9.1) (4.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.19.1->librosa==0.9.1) (3.2.0)\nRequirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.10/site-packages (from soundfile>=0.10.2->librosa==0.9.1) (1.16.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.5.2)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras) (2.17.2)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa==0.9.1) (2.21)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.3)\nDownloading librosa-0.9.1-py3-none-any.whl (213 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.1/213.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:02\u001b[0m\n\u001b[?25hDownloading keras-3.1.1-py3-none-any.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading optree-0.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (286 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.8/286.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: optree, ml-dtypes, tensorboard, resampy, librosa, keras, tensorflow\n  Attempting uninstall: ml-dtypes\n    Found existing installation: ml-dtypes 0.2.0\n    Uninstalling ml-dtypes-0.2.0:\n      Successfully uninstalled ml-dtypes-0.2.0\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.15.1\n    Uninstalling tensorboard-2.15.1:\n      Successfully uninstalled tensorboard-2.15.1\n  Attempting uninstall: librosa\n    Found existing installation: librosa 0.10.1\n    Uninstalling librosa-0.10.1:\n      Successfully uninstalled librosa-0.10.1\n  Attempting uninstall: keras\n    Found existing installation: keras 3.0.5\n    Uninstalling keras-3.0.5:\n      Successfully uninstalled keras-3.0.5\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.15.0\n    Uninstalling tensorflow-2.15.0:\n      Successfully uninstalled tensorflow-2.15.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\ntensorflow-decision-forests 1.8.1 requires tensorflow~=2.15.0, but you have tensorflow 2.16.1 which is incompatible.\ntensorflow-text 2.15.0 requires tensorflow<2.16,>=2.15.0; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.16.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed keras-3.1.1 librosa-0.9.1 ml-dtypes-0.3.2 optree-0.10.0 resampy-0.4.3 tensorboard-2.16.2 tensorflow-2.16.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport pandas as pd\nimport numpy as np\nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport librosa\nimport librosa.display\nfrom IPython.display import Audio\nfrom sklearn.preprocessing import OneHotEncoder\nfrom keras.models import Sequential\nfrom keras.layers import GRU, Bidirectional, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dropout, Dense","metadata":{"execution":{"iopub.status.busy":"2024-03-20T02:50:02.896435Z","iopub.execute_input":"2024-03-20T02:50:02.897463Z","iopub.status.idle":"2024-03-20T02:50:02.904401Z","shell.execute_reply.started":"2024-03-20T02:50:02.897415Z","shell.execute_reply":"2024-03-20T02:50:02.903278Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"#### Data Preprocessing","metadata":{}},{"cell_type":"code","source":"# Load train filenames and transcriptions from CSV\ntrain_df = pd.read_csv('/kaggle/input/train-metadata-final/metadata_train_final.csv')\ntrain_df['intent'] = train_df['intent'].str.lower()\n\n# Load validation filenames and transcriptions from CSV\n# validate_df = pd.read_csv('metadata_validate_final.csv')\n# validate_df['intent'] = validate_df['intent'].str.lower()","metadata":{"execution":{"iopub.status.busy":"2024-03-20T02:26:50.442698Z","iopub.execute_input":"2024-03-20T02:26:50.443018Z","iopub.status.idle":"2024-03-20T02:26:50.461725Z","shell.execute_reply.started":"2024-03-20T02:26:50.442994Z","shell.execute_reply":"2024-03-20T02:26:50.460883Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_df","metadata":{"execution":{"iopub.status.busy":"2024-03-20T02:26:51.336107Z","iopub.execute_input":"2024-03-20T02:26:51.336766Z","iopub.status.idle":"2024-03-20T02:26:51.347853Z","shell.execute_reply.started":"2024-03-20T02:26:51.336734Z","shell.execute_reply":"2024-03-20T02:26:51.346906Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                          file_name  label                intent\n0     1249120_43453425_58166571.wav     10         mental health\n1     1249120_43719934_43347848.wav      6  hair and skin issues\n2     1249120_43719934_53187202.wav      0            chest pain\n3     1249120_31349958_55816195.wav      8                injury\n4     1249120_43719934_82524191.wav      8                injury\n...                             ...    ...                   ...\n5890  1249120_14353703_45949288.wav      1      digestive issues\n5891  1249120_15004831_26452554.wav      8                injury\n5892  1249120_15004831_64958100.wav     11           muscle pain\n5893  1249120_15830408_92962528.wav      0            chest pain\n5894  1249120_15004831_80093096.wav      6  hair and skin issues\n\n[5895 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file_name</th>\n      <th>label</th>\n      <th>intent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1249120_43453425_58166571.wav</td>\n      <td>10</td>\n      <td>mental health</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1249120_43719934_43347848.wav</td>\n      <td>6</td>\n      <td>hair and skin issues</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1249120_43719934_53187202.wav</td>\n      <td>0</td>\n      <td>chest pain</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1249120_31349958_55816195.wav</td>\n      <td>8</td>\n      <td>injury</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1249120_43719934_82524191.wav</td>\n      <td>8</td>\n      <td>injury</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5890</th>\n      <td>1249120_14353703_45949288.wav</td>\n      <td>1</td>\n      <td>digestive issues</td>\n    </tr>\n    <tr>\n      <th>5891</th>\n      <td>1249120_15004831_26452554.wav</td>\n      <td>8</td>\n      <td>injury</td>\n    </tr>\n    <tr>\n      <th>5892</th>\n      <td>1249120_15004831_64958100.wav</td>\n      <td>11</td>\n      <td>muscle pain</td>\n    </tr>\n    <tr>\n      <th>5893</th>\n      <td>1249120_15830408_92962528.wav</td>\n      <td>0</td>\n      <td>chest pain</td>\n    </tr>\n    <tr>\n      <th>5894</th>\n      <td>1249120_15004831_80093096.wav</td>\n      <td>6</td>\n      <td>hair and skin issues</td>\n    </tr>\n  </tbody>\n</table>\n<p>5895 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_files = []\ntrain_intents = []\n\nfor file_name, intent in zip(train_df['file_name'], train_df['intent']):\n    train_files.append(f\"/kaggle/input/train-audio-classification/train/{file_name}\")\n    train_intents.append(intent)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T02:26:52.116490Z","iopub.execute_input":"2024-03-20T02:26:52.116865Z","iopub.status.idle":"2024-03-20T02:26:52.127367Z","shell.execute_reply.started":"2024-03-20T02:26:52.116835Z","shell.execute_reply":"2024-03-20T02:26:52.126276Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_df = pd.DataFrame({\n    'filename': train_files,\n    'intent': train_intents\n})","metadata":{"execution":{"iopub.status.busy":"2024-03-20T02:26:53.970329Z","iopub.execute_input":"2024-03-20T02:26:53.970694Z","iopub.status.idle":"2024-03-20T02:26:53.977081Z","shell.execute_reply.started":"2024-03-20T02:26:53.970653Z","shell.execute_reply":"2024-03-20T02:26:53.976024Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_df","metadata":{"execution":{"iopub.status.busy":"2024-03-20T02:26:54.861614Z","iopub.execute_input":"2024-03-20T02:26:54.862003Z","iopub.status.idle":"2024-03-20T02:26:54.872805Z","shell.execute_reply.started":"2024-03-20T02:26:54.861976Z","shell.execute_reply":"2024-03-20T02:26:54.871614Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"                                               filename                intent\n0     /kaggle/input/train-audio-classification/train...         mental health\n1     /kaggle/input/train-audio-classification/train...  hair and skin issues\n2     /kaggle/input/train-audio-classification/train...            chest pain\n3     /kaggle/input/train-audio-classification/train...                injury\n4     /kaggle/input/train-audio-classification/train...                injury\n...                                                 ...                   ...\n5890  /kaggle/input/train-audio-classification/train...      digestive issues\n5891  /kaggle/input/train-audio-classification/train...                injury\n5892  /kaggle/input/train-audio-classification/train...           muscle pain\n5893  /kaggle/input/train-audio-classification/train...            chest pain\n5894  /kaggle/input/train-audio-classification/train...  hair and skin issues\n\n[5895 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>intent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/train-audio-classification/train...</td>\n      <td>mental health</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/train-audio-classification/train...</td>\n      <td>hair and skin issues</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/train-audio-classification/train...</td>\n      <td>chest pain</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/train-audio-classification/train...</td>\n      <td>injury</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/train-audio-classification/train...</td>\n      <td>injury</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5890</th>\n      <td>/kaggle/input/train-audio-classification/train...</td>\n      <td>digestive issues</td>\n    </tr>\n    <tr>\n      <th>5891</th>\n      <td>/kaggle/input/train-audio-classification/train...</td>\n      <td>injury</td>\n    </tr>\n    <tr>\n      <th>5892</th>\n      <td>/kaggle/input/train-audio-classification/train...</td>\n      <td>muscle pain</td>\n    </tr>\n    <tr>\n      <th>5893</th>\n      <td>/kaggle/input/train-audio-classification/train...</td>\n      <td>chest pain</td>\n    </tr>\n    <tr>\n      <th>5894</th>\n      <td>/kaggle/input/train-audio-classification/train...</td>\n      <td>hair and skin issues</td>\n    </tr>\n  </tbody>\n</table>\n<p>5895 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_df['intent'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-03-20T02:27:24.988384Z","iopub.execute_input":"2024-03-20T02:27:24.989343Z","iopub.status.idle":"2024-03-20T02:27:25.004387Z","shell.execute_reply.started":"2024-03-20T02:27:24.989306Z","shell.execute_reply":"2024-03-20T02:27:25.003346Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"intent\nmuscle pain             1255\nhair and skin issues     764\ninjury                   664\nfoot pain                472\nrespiratory issue        470\nsensory issue            458\ndizziness                256\nchest pain               231\nhead ache                231\nfeeling cold/hot         230\ndigestive issues         230\ngeneral weakness         215\ninternal pain            215\nmental health            204\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"min_samples_per_intent = train_df.groupby('intent').size().min()\n\n# Sample the DataFrame for each intent class to get the desired number of samples\ntrain_df = train_df.groupby('intent', group_keys=False).apply(lambda x: x.sample(min_samples_per_intent))\n\n# Reset index of the sampled DataFrame\ntrain_df.reset_index(drop=True, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T02:27:26.250699Z","iopub.execute_input":"2024-03-20T02:27:26.251578Z","iopub.status.idle":"2024-03-20T02:27:26.270670Z","shell.execute_reply.started":"2024-03-20T02:27:26.251539Z","shell.execute_reply":"2024-03-20T02:27:26.269696Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"train_df['intent'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-03-20T02:27:27.456080Z","iopub.execute_input":"2024-03-20T02:27:27.456416Z","iopub.status.idle":"2024-03-20T02:27:27.465053Z","shell.execute_reply.started":"2024-03-20T02:27:27.456392Z","shell.execute_reply":"2024-03-20T02:27:27.464036Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"intent\nchest pain              204\ndigestive issues        204\ndizziness               204\nfeeling cold/hot        204\nfoot pain               204\ngeneral weakness        204\nhair and skin issues    204\nhead ache               204\ninjury                  204\ninternal pain           204\nmental health           204\nmuscle pain             204\nrespiratory issue       204\nsensory issue           204\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"#### Feature Extraction","metadata":{}},{"cell_type":"code","source":"def extract_mfcc(filename):\n    y, sr = librosa.load(filename, duration=8, offset=0.5)\n    mfcc = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40).T, axis=0)\n    return mfcc","metadata":{"execution":{"iopub.status.busy":"2024-03-20T02:27:31.128757Z","iopub.execute_input":"2024-03-20T02:27:31.129500Z","iopub.status.idle":"2024-03-20T02:27:31.134904Z","shell.execute_reply.started":"2024-03-20T02:27:31.129468Z","shell.execute_reply":"2024-03-20T02:27:31.133745Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"extract_mfcc(train_df['filename'][484])","metadata":{"execution":{"iopub.status.busy":"2024-03-20T02:27:31.875809Z","iopub.execute_input":"2024-03-20T02:27:31.876169Z","iopub.status.idle":"2024-03-20T02:27:33.329067Z","shell.execute_reply.started":"2024-03-20T02:27:31.876141Z","shell.execute_reply":"2024-03-20T02:27:33.327640Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"array([-3.2453796e+02,  1.5181155e+02, -8.3627424e+00,  1.8127216e+01,\n        3.1863151e+00,  5.0795736e+00,  6.8731689e+00,  1.6032633e+00,\n       -1.0545517e+00,  6.7843323e+00, -9.2558460e+00,  8.7427855e+00,\n       -1.4072841e+00,  5.8018255e+00,  8.2681856e+00,  2.7569058e+00,\n        8.4719521e-01,  7.9460282e+00, -4.3127213e+00,  5.1337667e+00,\n       -1.7130418e-01,  7.5766139e+00, -3.5493451e-01,  7.7652445e+00,\n        1.2889872e+00,  6.3668771e+00, -6.8194902e-01,  5.6029043e+00,\n       -1.7059224e+00,  2.7381787e+00,  2.3384645e+00,  2.0479071e+00,\n       -6.3767356e-01,  1.7218281e+00, -2.0435250e+00,  1.1490377e+00,\n       -1.4560053e+00,  2.2223242e-01, -1.5129106e+00,  1.5885150e+00],\n      dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"X_mfcc = train_df['filename'].apply(lambda x: extract_mfcc(x))\nX_mfcc","metadata":{"execution":{"iopub.status.busy":"2024-03-20T02:27:34.576388Z","iopub.execute_input":"2024-03-20T02:27:34.577286Z","iopub.status.idle":"2024-03-20T02:38:44.945692Z","shell.execute_reply.started":"2024-03-20T02:27:34.577253Z","shell.execute_reply":"2024-03-20T02:38:44.944360Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"0       [-297.50266, 51.646576, 1.9694555, 12.192121, ...\n1       [-522.0002, 106.7206, -14.634256, 34.310047, -...\n2       [-264.29233, 131.25223, -3.0252275, 12.848872,...\n3       [-306.3366, 123.03135, -12.331156, 21.2125, -1...\n4       [-461.34543, 195.18999, 27.279205, -0.02898660...\n                              ...                        \n2851    [-336.18207, 101.09681, -51.51952, 29.08254, -...\n2852    [-307.5957, 61.80122, 12.749242, 14.058215, 3....\n2853    [-353.21185, 130.57845, -8.485679, 13.764009, ...\n2854    [-479.44928, 124.76472, 28.798885, 3.1377325, ...\n2855    [-483.18253, 191.72531, 32.272778, 1.9935544, ...\nName: filename, Length: 2856, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"X = [x for x in X_mfcc]\nX = np.array(X)\nX.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-20T02:38:44.948334Z","iopub.execute_input":"2024-03-20T02:38:44.949109Z","iopub.status.idle":"2024-03-20T02:38:44.963072Z","shell.execute_reply.started":"2024-03-20T02:38:44.949064Z","shell.execute_reply":"2024-03-20T02:38:44.961702Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"(2856, 40)"},"metadata":{}}]},{"cell_type":"code","source":"## input split\nX = np.expand_dims(X, -1)\nX.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-20T02:38:44.965055Z","iopub.execute_input":"2024-03-20T02:38:44.965902Z","iopub.status.idle":"2024-03-20T02:38:44.977818Z","shell.execute_reply.started":"2024-03-20T02:38:44.965852Z","shell.execute_reply":"2024-03-20T02:38:44.976258Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"(2856, 40, 1)"},"metadata":{}}]},{"cell_type":"code","source":"enc = OneHotEncoder()\ny = enc.fit_transform(train_df[['intent']])","metadata":{"execution":{"iopub.status.busy":"2024-03-20T02:38:44.981839Z","iopub.execute_input":"2024-03-20T02:38:44.982312Z","iopub.status.idle":"2024-03-20T02:38:45.002692Z","shell.execute_reply.started":"2024-03-20T02:38:44.982269Z","shell.execute_reply":"2024-03-20T02:38:45.001467Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"y = y.toarray()\ny.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-20T02:38:45.009278Z","iopub.execute_input":"2024-03-20T02:38:45.014081Z","iopub.status.idle":"2024-03-20T02:38:45.033623Z","shell.execute_reply.started":"2024-03-20T02:38:45.014032Z","shell.execute_reply":"2024-03-20T02:38:45.032332Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"(2856, 14)"},"metadata":{}}]},{"cell_type":"markdown","source":"#### Model","metadata":{}},{"cell_type":"code","source":"model = Sequential([\n    Bidirectional(GRU(256, return_sequences=True), input_shape=(40,1)),  # Bidirectional GRU layer\n    Conv1D(128, kernel_size=3, activation='relu'),  # 1D Convolutional layer\n    MaxPooling1D(pool_size=2),  # Max pooling layer\n    Dropout(0.2),\n    GlobalMaxPooling1D(),  # Global max pooling layer\n    Dense(128, activation='relu'),  \n    Dropout(0.2),\n    Dense(64, activation='relu'),\n    Dropout(0.2),\n    Dense(14, activation='softmax')\n])\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-03-20T02:54:15.892232Z","iopub.execute_input":"2024-03-20T02:54:15.892908Z","iopub.status.idle":"2024-03-20T02:54:16.018006Z","shell.execute_reply.started":"2024-03-20T02:54:15.892877Z","shell.execute_reply":"2024-03-20T02:54:16.017178Z"},"trusted":true},"execution_count":40,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_4\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │       \u001b[38;5;34m397,824\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │       \u001b[38;5;34m196,736\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_14 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_max_pooling1d_1          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_15 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_16 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)             │           \u001b[38;5;34m910\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">397,824</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">196,736</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_max_pooling1d_1          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">910</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m620,238\u001b[0m (2.37 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">620,238</span> (2.37 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m620,238\u001b[0m (2.37 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">620,238</span> (2.37 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"# Train the model\nhistory = model.fit(X, y, validation_split=0.2, epochs=50, batch_size=64)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T02:54:16.522082Z","iopub.execute_input":"2024-03-20T02:54:16.522933Z","iopub.status.idle":"2024-03-20T02:54:41.472754Z","shell.execute_reply.started":"2024-03-20T02:54:16.522897Z","shell.execute_reply":"2024-03-20T02:54:41.471939Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"Epoch 1/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.0963 - loss: 2.6696 - val_accuracy: 0.0000e+00 - val_loss: 3.7159\nEpoch 2/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0963 - loss: 2.5239 - val_accuracy: 0.0000e+00 - val_loss: 3.8473\nEpoch 3/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1030 - loss: 2.4985 - val_accuracy: 0.0000e+00 - val_loss: 3.9536\nEpoch 4/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0891 - loss: 2.4998 - val_accuracy: 0.0000e+00 - val_loss: 4.1383\nEpoch 5/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0920 - loss: 2.4952 - val_accuracy: 0.0000e+00 - val_loss: 4.6168\nEpoch 6/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0887 - loss: 2.4801 - val_accuracy: 0.0000e+00 - val_loss: 4.2808\nEpoch 7/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0820 - loss: 2.4762 - val_accuracy: 0.0000e+00 - val_loss: 4.5133\nEpoch 8/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1017 - loss: 2.4701 - val_accuracy: 0.0000e+00 - val_loss: 4.5819\nEpoch 9/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0925 - loss: 2.4573 - val_accuracy: 0.0000e+00 - val_loss: 4.1738\nEpoch 10/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1006 - loss: 2.4639 - val_accuracy: 0.0000e+00 - val_loss: 4.7243\nEpoch 11/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0960 - loss: 2.4675 - val_accuracy: 0.0000e+00 - val_loss: 5.0012\nEpoch 12/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0991 - loss: 2.4660 - val_accuracy: 0.0000e+00 - val_loss: 5.1529\nEpoch 13/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0996 - loss: 2.4560 - val_accuracy: 0.0000e+00 - val_loss: 4.8051\nEpoch 14/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1133 - loss: 2.4351 - val_accuracy: 0.0000e+00 - val_loss: 5.0850\nEpoch 15/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1108 - loss: 2.4437 - val_accuracy: 0.0000e+00 - val_loss: 5.4347\nEpoch 16/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1038 - loss: 2.4588 - val_accuracy: 0.0000e+00 - val_loss: 5.0249\nEpoch 17/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1171 - loss: 2.4418 - val_accuracy: 0.0000e+00 - val_loss: 5.7812\nEpoch 18/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0989 - loss: 2.4406 - val_accuracy: 0.0000e+00 - val_loss: 4.8000\nEpoch 19/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1104 - loss: 2.4459 - val_accuracy: 0.0000e+00 - val_loss: 5.2163\nEpoch 20/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1153 - loss: 2.4430 - val_accuracy: 0.0000e+00 - val_loss: 5.5273\nEpoch 21/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1231 - loss: 2.4281 - val_accuracy: 0.0000e+00 - val_loss: 5.6137\nEpoch 22/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1150 - loss: 2.4229 - val_accuracy: 0.0000e+00 - val_loss: 5.7192\nEpoch 23/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1319 - loss: 2.4291 - val_accuracy: 0.0000e+00 - val_loss: 5.2417\nEpoch 24/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1321 - loss: 2.4259 - val_accuracy: 0.0000e+00 - val_loss: 5.8933\nEpoch 25/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0994 - loss: 2.4270 - val_accuracy: 0.0000e+00 - val_loss: 5.9323\nEpoch 26/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1291 - loss: 2.4103 - val_accuracy: 0.0000e+00 - val_loss: 5.9862\nEpoch 27/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1250 - loss: 2.4102 - val_accuracy: 0.0000e+00 - val_loss: 5.9754\nEpoch 28/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1457 - loss: 2.3995 - val_accuracy: 0.0000e+00 - val_loss: 6.1469\nEpoch 29/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1331 - loss: 2.4092 - val_accuracy: 0.0000e+00 - val_loss: 6.1713\nEpoch 30/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1372 - loss: 2.3995 - val_accuracy: 0.0000e+00 - val_loss: 5.6348\nEpoch 31/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1497 - loss: 2.3935 - val_accuracy: 0.0000e+00 - val_loss: 6.0669\nEpoch 32/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1351 - loss: 2.3852 - val_accuracy: 0.0000e+00 - val_loss: 5.8040\nEpoch 33/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1592 - loss: 2.3679 - val_accuracy: 0.0000e+00 - val_loss: 5.8556\nEpoch 34/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1458 - loss: 2.3974 - val_accuracy: 0.0000e+00 - val_loss: 6.7694\nEpoch 35/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1587 - loss: 2.3735 - val_accuracy: 0.0000e+00 - val_loss: 6.5025\nEpoch 36/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1610 - loss: 2.3843 - val_accuracy: 0.0000e+00 - val_loss: 6.4313\nEpoch 37/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1584 - loss: 2.3564 - val_accuracy: 0.0000e+00 - val_loss: 6.5591\nEpoch 38/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1688 - loss: 2.3382 - val_accuracy: 0.0000e+00 - val_loss: 6.8292\nEpoch 39/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1700 - loss: 2.3236 - val_accuracy: 0.0000e+00 - val_loss: 7.2099\nEpoch 40/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1573 - loss: 2.3548 - val_accuracy: 0.0000e+00 - val_loss: 6.9585\nEpoch 41/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1766 - loss: 2.3402 - val_accuracy: 0.0000e+00 - val_loss: 7.6308\nEpoch 42/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1858 - loss: 2.3034 - val_accuracy: 0.0000e+00 - val_loss: 7.3602\nEpoch 43/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1981 - loss: 2.3044 - val_accuracy: 0.0000e+00 - val_loss: 8.0748\nEpoch 44/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1935 - loss: 2.2771 - val_accuracy: 0.0000e+00 - val_loss: 7.1790\nEpoch 45/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1957 - loss: 2.2798 - val_accuracy: 0.0000e+00 - val_loss: 7.9856\nEpoch 46/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2141 - loss: 2.2250 - val_accuracy: 0.0017 - val_loss: 6.7679\nEpoch 47/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2137 - loss: 2.2342 - val_accuracy: 0.0000e+00 - val_loss: 7.3799\nEpoch 48/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2139 - loss: 2.2305 - val_accuracy: 0.0000e+00 - val_loss: 7.9982\nEpoch 49/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2395 - loss: 2.1958 - val_accuracy: 0.0052 - val_loss: 7.3627\nEpoch 50/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2131 - loss: 2.1905 - val_accuracy: 0.0000e+00 - val_loss: 7.8241\n","output_type":"stream"}]},{"cell_type":"code","source":"# Save the model and history\nmodel.save('model_audio_classification_1.h5')\n\n# Save history to a file\nimport json\n\nwith open('history_audio_classification_1.json', 'w') as f:\n    json.dump(history.history, f)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}